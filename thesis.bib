@Book{Leunen:Scholars:1992,
  author 			=	{Mary-Claire Van Leunen},
  title 			= {A Handbook for Scholars},
  publisher 	= {Oxford University Press},
  year 				= 1992
}

@Article {Zuber-Skerritt:ThesisWriting:1986,
   author 		= {Ortrun Zuber-Skerritt and Nick Knight},
   title 			= {Problem definition and thesis writing},
   journal 		= {Higher Education},
   publisher 	= {Springer Netherlands},
   issn 			= {0018-1560},
   pages 			= {89--103},
   volume 		= {15},
   issue 			= {1},
   year 			= {1986}
}

@article{szegedy2014intriguing,
  title   = {Intriguing Properties of Neural Networks},
  author  = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal = {arXiv preprint arXiv:1312.6199},
  year    = {2014}
}

@article{goodfellow2015explaining,
  title   = {Explaining and Harnessing Adversarial Examples},
  author  = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal = {arXiv preprint arXiv:1412.6572},
  year    = {2015}
}

@article{flinkow2025property,
  title   = {A General Framework for Property-Driven Machine Learning},
  author  = {Flinkow, Thomas and Casadio, Marco and Kessler, Colin and Monahan, Rosemary and Komendantskaya, Ekaterina},
  journal = {arXiv preprint arXiv:2505.00466},
  year    = {2025}
}

@inproceedings{casadio2023antonio,
  title     = {{ANTONIO}: Towards a Systematic Method for Generating NLP Benchmarks for Verification},
  author    = {Casadio, Marco and Arnaboldi, Luca and Daggitt, Matthew L and Isac, Omri and Dinkar, Tanvi and Kienitz, Daniel and Rieser, Verena and Komendantskaya, Ekaterina},
  booktitle = {Proceedings of the 6th Workshop on Formal Methods for ML-Enabled Autonomous Systems (FoMLAS)},
  year      = {2023}
}

@inproceedings{daggitt2025vehicle,
  title     = {Vehicle: Bridging the Embedding Gap in the Verification of Neuro-Symbolic Programs},
  author    = {Daggitt, Matthew L and Kokke, Wen and Atkey, Robert and Komendantskaya, Ekaterina and Slusarz, Natalia and Arnaboldi, Luca},
  booktitle = {Proceedings of the 10th International Conference on Formal Structures for Computation and Deduction (FSCD)},
  series    = {LIPIcs},
  year      = {2025}
}

@InProceedings{casadio2022neural,
  author="Casadio, Marco
  and Komendantskaya, Ekaterina
  and Daggitt, Matthew L.
  and Kokke, Wen
  and Katz, Guy
  and Amir, Guy
  and Refaeli, Idan",
  editor="Shoham, Sharon
  and Vizel, Yakir",
  title="Neural Network Robustness as a Verification Property: A Principled Case Study",
  booktitle="Computer Aided Verification",
  year="2022",
  publisher="Springer International Publishing",
  address="Cham",
  pages="219--231",
  abstract="Neural networks are very successful at detecting patterns in noisy data, and have become the technology of choice in many fields. However, their usefulness is hampered by their susceptibility to adversarial attacks. Recently, many methods for measuring and improving a network's robustness to adversarial perturbations have been proposed, and this growing body of research has given rise to numerous explicit or implicit notions of robustness. Connections between these notions are often subtle, and a systematic comparison between them is missing in the literature. In this paper we begin addressing this gap, by setting up general principles for the empirical analysis and evaluation of a network's robustness as a mathematical property---during the network's training phase, its verification, and after its deployment. We then apply these principles and conduct a case study that showcases the practical benefits of our general approach.",
  isbn="978-3-031-13185-1"
}

@InProceedings{reluplex2017efficient,
  author="Katz, Guy
  and Barrett, Clark
  and Dill, David L.
  and Julian, Kyle
  and Kochenderfer, Mykel J.",
  editor="Majumdar, Rupak
  and Kun{\v{c}}ak, Viktor",
  title="Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks",
  booktitle="Computer Aided Verification",
  year="2017",
  publisher="Springer International Publishing",
  address="Cham",
  pages="97--117",
  abstract="Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods.",
  isbn="978-3-319-63387-9"
}
